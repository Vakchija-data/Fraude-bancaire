{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0bbd761-f842-4c8f-922a-56b9f8f36739",
   "metadata": {},
   "source": [
    "## Toutes les catégories avec même taux de fraude --> taux de fraude ajusté proche de la réalité "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "151f08eb-8907-4e7a-8eb5-e2db30078616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97bc2c1b-61fe-4f1d-ab88-768b39834412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution souhaitée pour les fraudes\n",
    "FRAUD_DIST = {\n",
    "    \"Travel\": 0.40,\n",
    "    \"Retail\": 0.20,\n",
    "    \"Entertainment\": 0.15,\n",
    "    \"Restaurant\": 0.10,\n",
    "    \"Gas\": 0.07,\n",
    "    \"Grocery\": 0.05,\n",
    "    \"Healthcare\": 0.02,\n",
    "    \"Education\": 0.01\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28915efe-1883-4530-ab2f-975281ab7ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunk traité : 500000 lignes (fraudes rééchantillonnées)\n",
      "✅ Chunk traité : 500000 lignes (fraudes rééchantillonnées)\n",
      "✅ Chunk traité : 500000 lignes (fraudes rééchantillonnées)\n",
      "✅ Chunk traité : 500000 lignes (fraudes rééchantillonnées)\n",
      "✅ Chunk traité : 500000 lignes (fraudes rééchantillonnées)\n",
      "✅ Chunk traité : 500000 lignes (fraudes rééchantillonnées)\n",
      "✅ Chunk traité : 500000 lignes (fraudes rééchantillonnées)\n",
      "✅ Chunk traité : 500000 lignes (fraudes rééchantillonnées)\n",
      "✅ Chunk traité : 500000 lignes (fraudes rééchantillonnées)\n",
      "✅ Chunk traité : 500000 lignes (fraudes rééchantillonnées)\n",
      "✅ Chunk traité : 500000 lignes (fraudes rééchantillonnées)\n",
      "✅ Chunk traité : 500000 lignes (fraudes rééchantillonnées)\n",
      "✅ Chunk traité : 500000 lignes (fraudes rééchantillonnées)\n",
      "✅ Chunk traité : 500000 lignes (fraudes rééchantillonnées)\n",
      "✅ Chunk traité : 483766 lignes (fraudes rééchantillonnées)\n",
      "✅✅ Fichier final transactions_rebalanced.csv généré avec la distribution correcte pour les fraudes !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_file = \"transactions_clean.csv\"\n",
    "output_file = \"transactions_rebalanced_2.csv\"\n",
    "chunksize = 500_000  # ajustable selon RAM\n",
    "\n",
    "fraud_cats = list(FRAUD_DIST.keys())\n",
    "fraud_w = list(FRAUD_DIST.values())\n",
    "\n",
    "first_chunk = True  # pour écriture progressive\n",
    "\n",
    "# --------------------------\n",
    "# 2️⃣ Traitement chunk par chunk\n",
    "# --------------------------\n",
    "for chunk in pd.read_csv(input_file, chunksize=chunksize):\n",
    "\n",
    "    # Assurer que is_fraud est booléen\n",
    "    if chunk[\"is_fraud\"].dtype != \"bool\":\n",
    "        chunk[\"is_fraud\"] = chunk[\"is_fraud\"].astype(bool)\n",
    "\n",
    "    # Séparer les dataframes\n",
    "    df_fraud = chunk[chunk[\"is_fraud\"] == True].copy()\n",
    "    df_legit = chunk[chunk[\"is_fraud\"] == False].copy()\n",
    "\n",
    "    # --------------------------\n",
    "    # 3️⃣ Rééchantillonner df_fraud selon FRAUD_DIST\n",
    "    # --------------------------\n",
    "    df_fraud_sampled = pd.DataFrame()\n",
    "\n",
    "    for cat, prop in FRAUD_DIST.items():\n",
    "        subset = df_fraud[df_fraud[\"merchant_category\"] == cat]\n",
    "        n_samples = int(len(df_fraud) * prop)  # nombre de lignes à tirer\n",
    "        if len(subset) > 0:\n",
    "            n_samples = min(n_samples, len(subset))  \n",
    "            sampled = subset.sample(n=n_samples, replace=False)\n",
    "            df_fraud_sampled = pd.concat([df_fraud_sampled, sampled], axis=0)\n",
    "\n",
    "\n",
    "    # --------------------------\n",
    "    # 4️⃣ Concaténer df_fraud_sampled + df_legit\n",
    "    # --------------------------\n",
    "    final_chunk = pd.concat([df_fraud_sampled, df_legit], axis=0)\n",
    "\n",
    "    # --------------------------\n",
    "    # 5️⃣ Écriture progressive\n",
    "    # --------------------------\n",
    "    if first_chunk:\n",
    "        final_chunk.to_csv(output_file, index=False, mode=\"w\")\n",
    "        first_chunk = False\n",
    "    else:\n",
    "        final_chunk.to_csv(output_file, index=False, mode=\"a\", header=False)\n",
    "\n",
    "    print(f\"✅ Chunk traité : {len(chunk)} lignes (fraudes rééchantillonnées)\")\n",
    "\n",
    "print(\"✅✅ Fichier final transactions_rebalanced.csv généré avec la distribution correcte pour les fraudes !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "623f89de-3867-4aa2-9e25-0db5c38518a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "for chunk in pd.read_csv(\n",
    "    \"transactions_rebalanced_2.csv\",\n",
    "    usecols=[\"country\", \"is_fraud\", \"merchant_category\"],\n",
    "    chunksize=300_000\n",
    "):\n",
    "    grouped = (\n",
    "        chunk\n",
    "        .groupby([\"country\", \"is_fraud\", \"merchant_category\"])\n",
    "        .size()\n",
    "    )\n",
    "    counter.update(grouped.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "714ad9c1-e9ff-4d8d-a5eb-eb28c5da45a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts = (\n",
    "    pd.DataFrame.from_dict(counter, orient=\"index\", columns=[\"count\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_counts[[\"country\", \"is_fraud\", \"merchant_category\"]] = pd.DataFrame(\n",
    "    df_counts[\"index\"].tolist(),\n",
    "    index=df_counts.index\n",
    ")\n",
    "\n",
    "df_counts = df_counts.drop(columns=\"index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ade5691-c602-468c-b35d-a1ce801d582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts[\"distribution\"] = (\n",
    "    (df_counts[\"count\"]\n",
    "    / df_counts.groupby([\"country\", \"is_fraud\"])[\"count\"].transform(\"sum\"))*100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d57eda2-0721-4afc-8f0a-56137306f55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>is_fraud</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>12.477946</td>\n",
       "      <td>1.559657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entertainment</th>\n",
       "      <td>12.509845</td>\n",
       "      <td>19.997853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gas</th>\n",
       "      <td>12.500017</td>\n",
       "      <td>11.210540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grocery</th>\n",
       "      <td>12.473410</td>\n",
       "      <td>7.951449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Healthcare</th>\n",
       "      <td>12.524003</td>\n",
       "      <td>3.191814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Restaurant</th>\n",
       "      <td>12.509679</td>\n",
       "      <td>16.026061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retail</th>\n",
       "      <td>12.510897</td>\n",
       "      <td>19.917513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Travel</th>\n",
       "      <td>12.494203</td>\n",
       "      <td>20.145112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "is_fraud               False      True \n",
       "merchant_category                      \n",
       "Education          12.477946   1.559657\n",
       "Entertainment      12.509845  19.997853\n",
       "Gas                12.500017  11.210540\n",
       "Grocery            12.473410   7.951449\n",
       "Healthcare         12.524003   3.191814\n",
       "Restaurant         12.509679  16.026061\n",
       "Retail             12.510897  19.917513\n",
       "Travel             12.494203  20.145112"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot = df_counts.pivot_table(\n",
    "    index=\"merchant_category\",\n",
    "    columns=\"is_fraud\",\n",
    "    values=\"distribution\"\n",
    ")\n",
    "\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9fa8be-8daa-4167-8d56-8ebf81d2bed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
